# ü§ñ PROCESO K-NN ‚Äì TITANIC (de extremo a extremo)

## üìã Objetivo

Construir un clasificador K-Nearest Neighbors para predecir `Survival` en el Titanic y documentar con precisi√≥n operativa cada paso ejecutado: carga, validaci√≥n, selecci√≥n de variables, imputaci√≥n, codificaci√≥n, partici√≥n, escalado, optimizaci√≥n de K, entrenamiento, evaluaci√≥n, generaci√≥n de m√©tricas y visualizaciones.

## üîÑ Pipeline implementado (paso a paso exacto)

1. Carga de datos

- Implementaci√≥n: `src/data_processing/data_loader.py` ‚Üí `DataLoader.load_titanic_data()` (redirige a `load_csv`).
- Par√°metros de lectura: `low_memory=False`, `encoding='utf-8'` y dtypes espec√≠ficos:
  - `PassengerId:int32`, `Survived:int8`, `Pclass:int8`, `Age:float32`, `SibSp:int8`, `Parch:int8`, `Fare:float32`.
- Operaciones de logging: forma del dataset, tama√±o de archivo, uso de memoria, listado de columnas y tipos de datos.

2. Validaci√≥n de datos

- Implementaci√≥n: `DataLoader.validate_data(df)`.
- Salidas del validador:
  - Estructura: `shape`, columnas, `dtypes`, memoria (MB), filas duplicadas.
  - Calidad: conteo y porcentaje de nulos por columna.
  - Perfil num√©rico por columna num√©rica: media, desviaci√≥n, m√≠nimo, m√°ximo, conteo de ceros y de negativos.
  - Perfil categ√≥rico: cardinalidad, moda y frecuencia de la moda.

3. Selecci√≥n y transformaci√≥n inicial de variables

- Implementaci√≥n: `src/data_processing/data_preprocessor.py` ‚Üí `DataPreprocessor.select_features_for_classification(df)`.
- Operaciones exactas:
  - Eliminaci√≥n de columnas no utilizadas: `PassengerId`, `Name`, `Ticket`, `Cabin`.
  - Imputaci√≥n puntual:
    - `Age` ‚Üê mediana de `Age`.
    - `Embarked` ‚Üê moda de `Embarked`.
  - Codificaci√≥n con `pd.get_dummies(..., drop_first=True, dtype=int)`:
    - `Sex` ‚Üí `Sex_male` (1 = hombre, 0 = mujer).
    - `Embarked` ‚Üí `Embarked_Q`, `Embarked_S` (cuando ambos son 0, corresponde a Cherbourg).
  - Verificaci√≥n de `Survived` y retorno de un DataFrame con variables finales + objetivo.

4. Tratamiento formal de valores faltantes

- Implementaci√≥n: `DataPreprocessor.handle_missing_values(df, strategy='median')`.
- L√≥gica aplicada:
  - Separaci√≥n de columnas num√©ricas y categ√≥ricas.
  - Num√©ricas ‚Üí `SimpleImputer(strategy='median')` con persistencia en `self.imputers['numeric']`.
  - Categ√≥ricas ‚Üí `SimpleImputer(strategy='most_frequent')` con persistencia en `self.imputers['categorical']`.
  - Si `Survived` tiene nulos, se eliminan esas filas y se registra la cantidad removida.

5. (Definido, no activo por defecto) Remoci√≥n de outliers

- Implementaci√≥n disponible: `DataPreprocessor.remove_outliers(df, method='iqr', threshold=1.5)`.
- M√©todo IQR por columna num√©rica; preserva `Survived` y reporta filas removidas. En el pipeline por defecto, esta operaci√≥n est√° comentada y no se ejecuta.

6. Preparaci√≥n de caracter√≠sticas (X) y objetivo (y)

- Implementaci√≥n: `DataPreprocessor.prepare_features_target(df, target_column='Survived')`.
- Detalles de tipado:
  - `X = df.drop('Survived').astype('float64')`.
  - `y = df['Survived'].astype('int64')` (si fuese `object`, se usa `LabelEncoder`).
- Persistencia de metadatos: `feature_names` y `target_name` se almacenan para trazabilidad.

7. Divisi√≥n estratificada en entrenamiento y prueba

- Implementaci√≥n: `DataPreprocessor.split_data(X, y)`.
- Par√°metros efectivos: `test_size` y `random_state` desde `Config` (por defecto 0.2 y semilla fija). Se usa `stratify=y`.
- Fallback: si la estratificaci√≥n falla, se realiza divisi√≥n sin `stratify` (con advertencia). Se registran las formas de `X_train`, `X_test`, `y_train`, `y_test`.

8. Escalado de caracter√≠sticas

- Implementaci√≥n: `DataPreprocessor.scale_features(X_train, X_test)`.
- Algoritmo: `StandardScaler` (fit sobre train; transform sobre train y test). Devuelve `np.ndarray`. El scaler se guarda en `self.scaler`.

9. Optimizaci√≥n del hiperpar√°metro K

- Implementaci√≥n: `src/models/knn_classifier.py` ‚Üí `KNNClassifier.find_optimal_k(X_train_scaled, y_train)`.
- Proceso: para cada K en `Config.K_RANGE`, se ejecuta `cross_val_score(knn, X_train, y_train, cv=Config.CV_FOLDS, scoring='accuracy', n_jobs=-1)`.
- Resultados almacenados en `self.cv_results`: lista de K evaluados, medias y desviaciones est√°ndar por K, `best_k` y `best_score`.
- En la evaluaci√≥n actual, `best_k = 12`.

10. Entrenamiento del modelo

- Implementaci√≥n: `KNNClassifier.train(X_train_scaled, y_train, optimize_k=True)`.
- Par√°metros del estimador: `n_neighbors=12`, `metric='euclidean'`, `weights='uniform'` (a partir de `Config.get_model_config()` con ajuste de `n_neighbors`).
- M√©trica de entrenamiento registrada: `train_accuracy` a partir de predicci√≥n sobre `X_train_scaled`.

11. Evaluaci√≥n del modelo

- Ruta directa: `KNNClassifier.evaluate(X_test_scaled, y_test, class_names)` produce `accuracy`, `classification_report` (como dict) y `confusion_matrix`.
- Ruta integral: `src/evaluation/model_evaluator.py` ‚Üí `ModelEvaluator.evaluate_model(...)` a√±ade:
  - M√©tricas b√°sicas (train/test) y avanzadas (Cohen‚Äôs kappa, MCC) con `overfitting_score = train_accuracy - test_accuracy`.
  - M√©tricas por clase (precision, recall, f1, support) y an√°lisis de matriz de confusi√≥n (absoluta y normalizada por fila/columna/total; distribuci√≥n de clases reales y predichas; correctos/incorrectos; tasa de error).
  - Validaci√≥n cruzada (media, desviaci√≥n est√°ndar, min, max, lista de scores por fold).
  - Importancia de caracter√≠sticas por permutaci√≥n normalizada (si se proporcionan `feature_names`).
- Serializaci√≥n de resultados:
  - `ModelEvaluator.save_evaluation_report(filepath)` ‚Üí `results/evaluation_report.json`.
  - `ModelEvaluator.export_results_to_csv(filepath)` ‚Üí `results/metrics_summary.csv`.

12. Visualizaciones y guardado de im√°genes

- Implementaci√≥n: `ModelEvaluator.generate_visualizations(save_dir='results/model_visualizations', show_plots=False)`.
- Genera: `KNN_Titanic_Classifier_confusion_matrix.png` (matriz de confusi√≥n con anotaciones e interpretaci√≥n est√°ndar en el encabezado).
- La optimizaci√≥n de K puede graficarse desde el clasificador (`KNNClassifier.plot_k_optimization`) y, en el visualizador, con `plot_k_optimization(k_values, cv_scores_mean, cv_scores_std, best_k)`.

## ‚öôÔ∏è Configuraci√≥n final del KNN

- Tipo de modelo: `KNeighborsClassifier`.
- Hiperpar√°metros efectivos: `n_neighbors=12`, `metric='euclidean'`, `weights='uniform'`.
- Preprocesamiento requerido: estandarizaci√≥n con `StandardScaler` (fit en train, transform en test de la misma manera).

## üìà Resultados num√©ricos (seg√∫n evaluaci√≥n)

- Entrenamiento: Accuracy 0.8287.
- Prueba: Accuracy 0.8212; Balanced Accuracy 0.7870; Precision 0.8271; Recall 0.8212; F1 0.8146.
- M√©tricas avanzadas: Cohen‚Äôs Kappa 0.6034; MCC 0.6190.
- Overfitting score: 0.0074 (diferencia absoluta train‚Äìtest).
- Validaci√≥n cruzada (accuracy): media ‚âà 0.8203; std ‚âà 0.0329; min ‚âà 0.7762; max ‚âà 0.8732.

## üß© Matriz de confusi√≥n (desglose exacto)

- Matriz absoluta (test, 179 muestras):

```text
                 Predicci√≥n
             No Sobrevivi√≥   Sobrevivi√≥
Real
No Sobrevivi√≥        103            7
Sobrevivi√≥            25           44
```

- TN = 103
- FP = 7
- FN = 25
- TP = 44

- Normalizada por fila (recall por clase):

```text
No Sobrevivi√≥: [0.9364, 0.0636]
Sobrevivi√≥:   [0.3623, 0.6377]
```

- Normalizada por columna (precision por predicci√≥n):

```text
Pred ¬´No Sobrevivi√≥¬ª: [0.8047, 0.1953]
Pred ¬´Sobrevivi√≥¬ª:    [0.1373, 0.8627]
```

- Distribuciones: reales [110, 69]; predichas [128, 51].

- Lectura operativa: alta especificidad para ¬´No Sobrevivi√≥¬ª (recall 0.936) y alta precisi√≥n al predecir ¬´Sobrevivi√≥¬ª (0.863). La mayor masa de error son FN (25), es decir, sobrevivientes clasificados como no sobrevivientes.

## üåü Importancia de caracter√≠sticas (permutaci√≥n)

- Importancias normalizadas (suma ‚âà 1.0):

```text
Sex_male:   0.4983
SibSp:      0.1271
Pclass:     0.1187
Age:        0.1070
Parch:      0.0769
Fare:       0.0452
Embarked_S: 0.0151
Embarked_Q: 0.0117
```

- Lectura: `Sex_male` concentra la mayor contribuci√≥n marginal; le siguen v√≠nculos familiares (`SibSp`, `Parch`), clase del boleto (`Pclass`) y edad (`Age`).

## üîó Matriz de correlaci√≥n

- Prop√≥sito: cuantificar relaciones lineales entre variables num√©ricas utilizadas tras el preprocesamiento.
- Uso: identificar redundancias que afecten el c√°lculo de distancias en KNN y verificar coherencia de escalas tras estandarizaci√≥n.
- Patr√≥n esperable en Titanic: relaci√≥n entre `Pclass` y `Fare`, y asociaci√≥n entre `SibSp` y `Parch`.

## üîß Optimizaci√≥n de K

- ¬øQu√© es K y por qu√© es importante?:

  - K es el n√∫mero de vecinos m√°s cercanos considerados para clasificar una instancia. Determina el tama√±o del vecindario en el espacio de caracter√≠sticas.
  - Impacto directo en el sesgo‚Äìvarianza: K bajos (1‚Äì5) capturan ruido (sobreajuste); K altos hacen predicciones muy suavizadas (subajuste).
  - En KNN, K es el hiperpar√°metro cr√≠tico porque no existe un ajuste param√©trico interno: toda la flexibilidad del modelo est√° en la elecci√≥n del vecindario y la m√©trica.

- ¬øC√≥mo se calcula y selecciona K en este proyecto?:

  - Para cada valor de K en `Config.K_RANGE`, se entrena un KNN temporal con `n_neighbors=K` y se calcula su desempe√±o con `cross_val_score` (CV de `Config.CV_FOLDS`).
  - Se registran para cada K: el accuracy medio y su desviaci√≥n est√°ndar. Estos valores quedan guardados en `cv_results` (llaves: `k_values`, `cv_scores_mean`, `cv_scores_std`, `best_k`, `best_score`).
  - Se elige `best_k` como el K con mayor accuracy medio. En esta corrida, `best_k = 12`.

- Procedimiento: evaluaci√≥n por validaci√≥n cruzada para m√∫ltiples K, recopilando media y desviaci√≥n est√°ndar; selecci√≥n del mejor K (= 12) y registro en `cv_results` para reproducibilidad y graficaci√≥n.

## üóÇÔ∏è Artefactos generados

- `results/evaluation_report.json`
- `results/metrics_summary.csv`
- `results/model_visualizations/KNN_Titanic_Classifier_confusion_matrix.png`
- `results/model_visualizations/KNN_Titanic_Classifier_feature_importance.png`
- `results/correlation_matrix.png`
- `results/k_optimization.png`
